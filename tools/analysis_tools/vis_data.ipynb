{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) OpenMMLab. All rights reserved.\n",
    "import random\n",
    "random.seed(0)\n",
    "import argparse\n",
    "import os.path as osp\n",
    "\n",
    "from mmengine.config import Config, DictAction\n",
    "from mmengine.utils import ProgressBar\n",
    "\n",
    "from mmseg.registry import DATASETS, VISUALIZERS\n",
    "from mmseg.utils import register_all_modules\n",
    "\n",
    "from mmseg.datasets.transforms import LoadAnnotations_SAL, RandomFlip, RandomCrop, PhotoMetricDistortion, PackSegInputs\n",
    "from mmcv.transforms import RandomResize,LoadImageFromFile\n",
    "from mmseg.utils.misc import stack_batch\n",
    "\n",
    "from mmseg.models.data_preprocessor import SegDataPreProcessor\n",
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = '/media/ders/mazhiming/mmseg4wsss/mmsegmentation/data/VOCdevkit/VOC2012/JPEGImages/2007_000032.jpg'\n",
    "gt_path = '/media/ders/mazhiming/mmseg4wsss/mmsegmentation/data/VOCdevkit/VOC2012/SegmentationClass/2007_000032.png'\n",
    "sal_path = '/media/ders/mazhiming/mmseg4wsss/mmsegmentation/data/VOCdevkit/VOC2012/saliency_map/2007_000032.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalize:\n",
    "    def __init__(self, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, img):\n",
    "        img_arr = np.asarray(img)\n",
    "        normalized_img = np.empty_like(img_arr, np.float32)\n",
    "\n",
    "        normalized_img[..., 0] = (img_arr[..., 0] / 255. - self.mean[0]) / self.std[0]\n",
    "        normalized_img[..., 1] = (img_arr[..., 1] / 255. - self.mean[1]) / self.std[1]\n",
    "        normalized_img[..., 2] = (img_arr[..., 2] / 255. - self.mean[2]) / self.std[2]\n",
    "\n",
    "        return normalized_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomCrop=RandomCrop(crop_size=(448,448),cat_max_ratio=0.75)\n",
    "randomFlip=RandomFlip(prob=0.5)\n",
    "randomResize=RandomResize(ratio_range=(0.5, 2.0),scale=(256,512),keep_ratio=True)\n",
    "loadImg=LoadImageFromFile()\n",
    "loadAnn=LoadAnnotations_SAL()\n",
    "photoMetricDistortion=PhotoMetricDistortion(brightness_delta=77,contrast_range=(0.7,1.3),saturation_range=(0.7,1.3),hue_delta=26)#brightness_delta=77,contrast_range=(0.7,1.3),saturation_range=(0.7,1.3),hue_delta=0.1\n",
    "packSegInputs=PackSegInputs()\n",
    "normalize = Normalize()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = dict(\n",
    "    img_path=img_path,\n",
    "    seg_map_path=gt_path,\n",
    "    sal_path=sal_path,\n",
    "    reduce_zero_label=False,\n",
    "    seg_fields=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_img(results):\n",
    "    x=loadImg(results)\n",
    "    x=loadAnn(x)\n",
    "    x=randomResize(x)\n",
    "    \n",
    "    x=randomFlip(x)\n",
    "    x=photoMetricDistortion(x)#jetter\n",
    "    x=randomCrop(x)\n",
    "    x=packSegInputs(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=transform_img(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x['data_samples'].gt_sem_seg.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x['data_samples']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['data_samples'].sal_map.data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['inputs'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "img_or=plt.imread(img_path)\n",
    "plt.imshow(img_or)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize = Normalize()\n",
    "# x['inputs'] = normalize(x['inputs'])\n",
    "plt.imshow(x['inputs'].numpy().transpose(1,2,0)[...,::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x['data_samples'].sal_map.data.numpy().transpose(1,2,0)*255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#stack_batch func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean=[123.675, 116.28, 103.53]\n",
    "std=[58.395, 57.12, 57.375]\n",
    "pad_val=0\n",
    "seg_pad_val=255\n",
    "size=(448,448)\n",
    "type='SegDataPreProcessor'\n",
    "dataSamples=x['data_samples']\n",
    "inputs=x['inputs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputdata,padded_samples=stack_batch(inputs=[inputs], data_samples=[dataSamples],  size=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputdata.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(outputdata[0].numpy().transpose(1,2,0))\n",
    "# outputdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padded_samples[0].sal_map.data.size()\n",
    "# plt.imshow(padded_samples[0].sal_map.data.numpy().transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padded_samples[0].sal_map.data.max()\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segDataPpreprocessor=SegDataPreProcessor(bgr_to_rgb=True,\n",
    "    mean=[\n",
    "        123.675,\n",
    "        116.28,\n",
    "        103.53,\n",
    "    ],\n",
    "    pad_val=0,\n",
    "    seg_pad_val=0,\n",
    "    size=(\n",
    "        448,\n",
    "        448,\n",
    "    ),\n",
    "    std=[\n",
    "        58.395,\n",
    "        57.12,\n",
    "        57.375,\n",
    "    ],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['data_samples'].gt_sem_seg.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['inputs']=[x['inputs']]\n",
    "x['data_samples']=[x['data_samples']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_of_model=segDataPpreprocessor(x,training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_of_model['inputs'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_of_model['inputs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(input_of_model['inputs'][0].numpy().transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_of_model['data_samples'].sal_map.data.size()\n",
    "plt.imshow(input_of_model['data_samples'].sal_map.data.numpy().transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wsss_mmseg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
